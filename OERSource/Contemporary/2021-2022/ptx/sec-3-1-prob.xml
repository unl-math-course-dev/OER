<section xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="sec-3-1-prob">

	<title>Probability</title>

	<subsection><title>Introduction</title>
	<p>The probability of a specified event is the chance or likelihood that it will occur.  There are several ways of viewing probability.  One would be <term>experimental</term> in nature, where we repeatedly conduct an experiment.  Suppose we flipped a coin over and over and over again and it came up heads about half of the time; we would expect that in the future whenever we flipped the coin it would turn up heads about half of the time.  When a weather reporter says “there is a 10% chance of rain tomorrow,” she is basing that on prior evidence; that out of all days with similar weather patterns, it has rained on 1 out of 10 of those days.</p>

	<p>Another view would be <term>subjective</term> in nature, in other words an educated guess.  If someone asked you the probability that the Seattle Mariners would win their next baseball game, it would be impossible to conduct an experiment where the same two teams played each other repeatedly, each time with the same starting lineup and starting pitchers, each starting at the same time of day on the same field under the precisely the same conditions.  Since there are so many variables to take into account, someone familiar with baseball and with the two teams involved might make an educated guess that there is a 75% chance they will win the game; that is, if the same two teams were to play each other repeatedly under identical conditions, the Mariners would win about three out of every four games.  But this is just a guess, with no way to verify its accuracy, and depending upon how educated the educated guesser is, a subjective probability may not be worth very much.</p>

	<p>We will return to the experimental and subjective probabilities from time to time, but in this course we will mostly be concerned with <term>theoretical</term> probability, which is defined as follows: Suppose there is a situation with n <u>equally likely</u> possible outcomes and that m of those n outcomes correspond to a particular event; then the <term>probability</term> of that event is defined as <m> \frac{m}{n} </m>.</p>

</subsection>

<subsection><title>Basic Concepts</title>

	<p>If you roll a die, pick a card from deck of playing cards, or randomly select a person and observe their hair color, we are executing an experiment or procedure.  In probability, we look at the likelihood of different outcomes.  We begin with some terminology. </p>

	<assemblage>
		<title>Events and Outcomes</title>
		<p>The result of an experiment is called an <term>outcome</term>.  Outcomes must be <term>disjoint</term>, meaning that two different outcomes cannot happen at the same time; every time you perform the experiment, there is exactly one outcome.</p>

		<p>The <term>sample space</term> is the set of all possible outcomes.</p>

		<p>An <term>event</term> is any particular outcome or group of outcomes.  If an event includes multiple outcomes, it is known as a <term>compound event</term>; if it consists of exactly one outcome, i.e., it cannot be broken down further, it is known as a <term>simple event</term>.</p>

	</assemblage>

	<example>
		<p>If we roll a standard 6-sided die, describe the sample space and some events.</p>

		<p>The sample space is the set of all possible outcomes: {1,2,3,4,5,6}</p>

		<p>Some examples of simple events:

		<ul>
			<li>We roll a 1</li>
			<li>We roll a 5</li>
		</ul>
		</p>

		<p>Some compound events:

		<ul>
			<li>We roll a number bigger than 4</li>
			<li>We roll an even number</li>
		</ul>
		</p>

	</example>

	<assemblage>
		<title>Basic Probability</title>

		<p>The <term>probability</term> of an outcome or event is the proportion of times we should expect the outcome or event to occur if the experiment is run many times.</p>

		<p>Since outcomes are disjoint, the probability of an event is the sum of the probabilities of all the outcomes included in the event.</p>

		<p>If all outcomes of an experiment are equally likely, we can compute the probability of an event E using this formula:</p>

		<p><me>P(E) = \frac{\text{Number of outcomes corresponding to the event E}}{\text{Total number of equally likely outcomes}}</me></p>
	</assemblage>

	<example>
		<p>If we roll a 6-sided die, calculate:

			<ol>
				<li>P(rolling a 1)</li>
				<li>P(rolling a number greater than 4)</li>
			</ol>
		</p>

		<p>Recall that the possible outcomes are {1,2,3,4,5,6}</p>

		<p>
			<ol>
				<li>There is one outcome corresponding to “rolling a 1”, so the probability is <m>\frac{1}{6}</m></li>
				<li>There are two outcomes bigger than a 4, so the probability is <m>\frac{2}{6}=\frac{1}{3}</m></li>
			</ol>
		</p>
	</example>

<p>Probabilities are essentially fractions, and can be reduced to lower terms like fractions.</p>

<example>
	<p>Let's say you have a bag with 20 cherries, 14 sweet and 6 sour. If you pick a cherry at random, what is the probability that it will be sweet? </p>

	<p>There are 20 possible cherries that could be picked, so the number of possible outcomes is 20. Of these 20 possible outcomes, 14 are favorable (sweet), so the probability that the cherry will be sweet is <m> \frac{14}{20} = \frac{7}{10} </m>.</p>
</example>

<p>There is one potential complication to this example, however. It must be assumed that the probability of picking any of the cherries is the same as the probability of picking any other. This wouldn't be true if (let us imagine) the sweet cherries are smaller than the sour ones. (The sour cherries would come to hand more readily when you sampled from the bag.) Let us keep in mind, therefore, that when we assess probabilities in terms of the ratio of favorable to all potential cases, we rely heavily on the assumption of equal probability for all outcomes.</p>

<exploration>
	<p>At some random moment, you look at your clock and note the minutes reading.</p>

	<ol>
		<li>What is the probability the minutes reading is 15?</li>
		<li>What is the probability the minutes reading is 15 or less?</li>
	</ol>
</exploration>


<assemblage>
	<title>Cards</title>

	<p>A standard deck of 52 playing cards consists of four <term>suits</term> (hearts, spades, diamonds and clubs). Spades and clubs are black while hearts and diamonds are red. Each suit contains 13 cards, each of a different <term>rank</term>: an Ace (which in many games functions as both a low card and a high card), cards numbered 2 through 10, a Jack, a Queen and a King.</p>
</assemblage>

<example>
	<p>Compute the probability of randomly drawing one card from a deck and getting an Ace.</p>

	<p>There are 52 cards in the deck and 4 Aces so P(Ace) = <m>\frac{4}{52} = \frac{1}{13} \approx 0.0769 </m> </p>

	<p>We can also think of probabilities as percents: There is a 7.69% chance that a randomly selected card will be an Ace.</p>
</example>

<p>Notice that the smallest possible probability is 0 – if there are no outcomes that correspond with the event.  The largest possible probability is 1 – if all possible outcomes correspond with the event.</p>

<assemblage>
	<title>Certain and Impossible events</title>
	<p>An impossible event has a probability of 0.</p>
	<p>A certain event has a probability of 1.</p>
	<p>The probability of any event must be <m>0 \leq P(E) \leq 1</m></p>
</assemblage>

<p>In the course of this chapter, if you compute a probability and get an answer that is negative or greater than 1, you have made a mistake and should check your work.</p>

</subsection>

<subsection><title>Discrete Probability Distributions</title>

<p>It is often useful to list the probabilities of all possible outcomes of an experiment.  This can allow us to more easily compare events to each other and see other useful patterns in how probability is distributed between the outcomes.</p>

<assemblage>
	<title>Discrete Probability Distributions</title>

	<p>If an experiment has finitely many possible outcomes, then the <term>probability distribution</term> of the experiment is the list of outcomes and their associated probabilities.  It is typically given in a table or bar graph.</p>

	<p>The sum of the probabilities of all the outcomes is always 1 (or 100%), since there is a 100% chance that some outcome happens.</p>
</assemblage>

<exploration>
	<statement>
		<p>The table below suggests three possible probability distributions for the income of a randomly-chosen household in the United States, in thousands of dollars. Only one is correct. Which one must it be? What is wrong with the other two?</p>
		<sidebyside>
			<tabular halign="center" right="minor" left="minor" top="minor" bottom="minor">
				<row>
					<cell>Income range ($1000s)</cell>
					<cell>0-25</cell>
					<cell>25-50</cell>
					<cell>50-100</cell>
					<cell>100+</cell>
				</row>
				<row>
					<cell>(a)</cell>
					<cell>0.18</cell>
					<cell>0.39</cell>
					<cell>0.33</cell>
					<cell>0.16</cell>
				</row>
				<row>
					<cell>(b)</cell>
					<cell>0.28</cell>
					<cell>0.27</cell>
					<cell>0.29</cell>
					<cell>0.16</cell>
				</row>
				<row>
					<cell>(c)</cell>
					<cell>0.18</cell>
					<cell>-0.47</cell>
					<cell>1.12</cell>
					<cell>0.17</cell>
				</row>
			</tabular>
		</sidebyside>
	</statement>
	<solution>
		<p>Only distribution (b) is a valid probability distribution.  The probability of each outcome is between 0 and 1, and the probabilities together add to exactly 1.  The probabilities of distribution (a) add to 1.06, and some probabilities in distribution (c) are below 0 or above 1.</p>
	</solution>
</exploration>

<example>
	<title>The sum of two cards</title>

	<p>Suppose we take the 2, 3, 4, 5, 6, and 7 of spades from a deck of cards, shuffle these six cards, then add together the values of the top two cards.  The outcomes of this experiment are the possible sums: the integers 5 - 13.  Below is the probability distribution of this experiment, in table and graph form.  (It is possible to calculate the probability of each outcome by hand.  Try it yourself for an extra challenge!)</p>

	<sidebyside>
		<tabular halign="center" right="minor" left="minor" top="minor" bottom="minor">
			<row>
				<cell>Sum of card values</cell>
				<cell>5</cell>
				<cell>6</cell>
				<cell>7</cell>
				<cell>8</cell>
				<cell>9</cell>
				<cell>10</cell>
				<cell>11</cell>
				<cell>12</cell>
				<cell>13</cell>
			</row>
			<row>
				<cell>Probability</cell>
				<cell><m>\frac{1}{15}</m></cell>
				<cell><m>\frac{1}{15}</m></cell>
				<cell><m>\frac{2}{15}</m></cell>
				<cell><m>\frac{2}{15}</m></cell>
				<cell><m>\frac{1}{5}</m></cell>
				<cell><m>\frac{2}{15}</m></cell>
				<cell><m>\frac{2}{15}</m></cell>
				<cell><m>\frac{1}{15}</m></cell>
				<cell><m>\frac{1}{15}</m></cell>
			</row>
		</tabular>
	</sidebyside>

	<image href="images/two-cards-prob-dist.png"/>

	<p>The table allows us to quickly calculate the probability of any event:
		<ul>
			<li>The probability that the sum of the cards is either 7 or 13 is <me>\frac{2}{15} + \frac{1}{15} = \frac{3}{15} = \frac{1}{5} = 0.2,</me> or 20%.</li>
			<li>The probability that the sum of the cards is even is <me>\frac{1}{15} + \frac{2}{15} + \frac{2}{15} + \frac{1}{15} = \frac{6}{15} = \frac{2}{5} = 0.4,</me> or 40%.</li>
		</ul>
	</p>

	<p>The bar graph allows us to more easily see the way the probability is distributed over the possible outcomes.  For example, you likely noticed that this probability distribution is symmetric, centered at the outcome 9.  Therefore, if we performed this experiment many times, we should expect the average outcome to be 9.  We should also expect that an outcome greater than 11 is less likely than an outcome smaller than 8, since we can see that the area of the bars to the right of 11 is less than the area of the bars to the left of 8.</p>

</example>

<exploration xml:id="commute-example">
	<statement>
		<p>Consider the following probability distribution for the amount of time you spend commuting to work on a given day (rounded to the nearest number of minutes).</p>
		<image href="images/commute-length.png"/>
		<ol>
			<li>What is the probability that your commute takes 20 minutes or longer?</li>
			<li>Is it more likely that your commute takes more than 18 minutes or less than 16 minutes?</li>
			<li>If asked how long your commute takes, what number of minutes would you say?</li>
			<li>Do you think the average number of minutes you take to get to work is less than, greater than, or equal to the number you chose for the previous part?  If there is any difference, what do you think causes it?</li>
		</ol>
	</statement>
	<solution>
		<ol>
			<li><m>0.05+0.03+0.015+0.005 = 0.1</m> or 10%</li>
			<li>We could compute the probabilities, but looking at the graph it seems clear that there is more area in the bars to the right of 18 minutes than to the left of 16 minutes.  So we can confidently say, without any calculations, that it is more likely for your commute to take more than 18 minutes.</li>
			<li>This is certainly subjective, but if you had to simplify this to a single number, as people often do, 17 minutes probably makes the most sense.  Your commute takes between 16 and 18 minutes the majority (68%) of the time, and it most commonly takes 17 minutes.</li>
			<li>Unlike the previous example with the sum of two cards, this probability distribution is not symmetric; it trails off to the right.  This means that there is more probability on the right side of the peak.  Therefore, it's most likely that you will tend to take longer than 17 minutes on average.  This may be caused by the fact that random occurences that cause delays are likely to have a more significant impact on your commute than ones that save you time.  For example, a bad traffic day would probably cause a longer delay than the amount of time that particularly clear roads would save you.</li>
		</ol>
	</solution>
</exploration>

<exploration>
	<statement>
		<p>You may have seen a weather forecast giving the chance of rain over the course of a day in a bar graph that looks something like this:</p>

		<image source="images/weather-forecast.png"/>

		<p>Is this a probability distribution?  Explain why or why not.</p>
	</statement>
	<solution>
		<p>This graph is not a probability distribution.  The horizontal axis lists times of day that it could rain, and it is possible that it could rain across multiple times.  Since it could rain at 4:00pm and at 5:00pm, for example, these times cannot be considered the list of outcomes of an experiment.  You might also have noticed that the probabilities all together will add up to much more than 100%, which also reflects the fact that it could rain at multiple times throughout the day.</p>
	</solution>
</exploration>

</subsection>


<subsection><title>Continuous Probability Distributions</title>

	<p>So far, we have only looked at experiments with finitely many possible outcomes.  However, in some situations, it makes sense to consider the outcomes of an experiment to fall within a continous range of outcomes, in which case there are infinitely many possible outcomes.</p>

	<p>Consider again the probability distribution from <xref ref="commute-example"/>, regarding commute time.  In that Exploration, we considered the outcomes to be integer numbers of minutes for simplicity's sake, but we could add more detail.  A given commute might take closer to 17.25 minutes than 17 minutes, a level of precision that we ignored.  In theory, your commute could take any number of minutes, including decimal numbers of minutes like 16.326 or even 19.202002000200002....  Although we would never be able to measure your travel time with an infinite amount of precision, it makes sense to say that your actual travel time could be any of the infinitely-many real numbers within a reasonable range; all of these numbers are possible outcomes.</p>

	<p>There is an interesting consequence for probability when the outcomes of an experiment span a continous interval of numbers: the probability of any given outcome is typically 0.  To get some intuition for why this should be true, consider the following sequence of experiments: I'm going to write down a number between 0 and 1, and in the first experiment, you're going to guess whether my number falls into one of two intervals: is my number less than 0.5, or is it greater than or equal to 0.5?  In the second experiment, we'll split each interval in half, and you'll guess if my number falls in the interval 0-0.25, 0.25-0.5, 0.5-0.75, or 0.75-1.  We'll keep splitting the intervals in half forever: in the third experiment there will be 8 equal-sized intervals, in the fourth experiment there will be 16, and so on. Each time we play, the probability that you guess correctly is split in half: first the probability is 1/2, then 1/4, then 1/8, and so on, each time getting closer and closer to a probability of 0, though each time it is still possible for you to guess the correct interval.</p>

	<p>Now consider one final experiment: rather than guessing an interval that my number is contained in, I ask you to guess my number exactly.  What is the probability that you guess correctly?  Well, it's true that guessing the number exactly should be harder than guessing what interval it falls into, no matter how many intervals you're choosing between.  So the probability of guessing correctly in this case must be smaller than the probability of guessing correctly in each of the previous experiments.  What probability is less than each of 1/2, 1/4, 1/8, 1/16, and so on?  Only 0.</p>

	<p>In a similar way, the probability that your commute takes <i>exactly</i> 19.202002000200002... minutes, or <i>exactly</i> 19.00000000000001 minutes, or even <i>exactly</i> 19 minutes, to an infinite level of precision, is 0.  Such an outcome would have to be less likely than if <i>any</i> amount of error were allowed, no matter how small, implying that the probability must be 0.</p>

	<p>Because each outcome of this experiment has a probability of 0, listing the probability of each outcome or drawing a graph of the probability of each outcome isn't going to be useful to us like it was with discrete probability distributions.  However, given any interval of possible outcomes, there may be some non-zero probability that the outcome of the experiment falls within that interval; for example, there is some non-zero probability that your commute takes between 16 and 18 minutes, and a smaller probability that it takes between 16.23 and 16.25 minutes.  Our goal will be to find a way to convey the probability corresponding to an interval of minutes, for any interval you could choose.</p>

	

</subsection>










<!-- Material from before 2021

<subsection><title>Complementary Events</title>

<p>Now let us examine the probability that an event does <term>not</term> happen. As in the previous section, consider the situation of rolling a six-sided die and first compute the probability of rolling a six: the answer is P(six) =1/6. Now consider the probability that we do not roll a six: there are 5 outcomes that are not a six, so the answer is P(not a six) = <m> \frac{5}{6}</m> . Notice that P(six)+P(not a six) = <m> \frac{1}{6} + \frac{5}{6} = \frac{6}{6} = 1</m></p>

<p>This is not a coincidence.  Consider a generic situation with n possible outcomes and an event E that corresponds to m of these outcomes. Then the remaining n - m outcomes correspond to E not happening, thus</p>

<p>P(not E) = <m> \frac{n-m}{n} = \frac{n}{n}-\frac{m}{n}=1</m> - P(E) </p>

<assemblage>
	<title>Complement of an Event</title>
		<p>The <term>complement</term> of an event is the event "E doesn't happen".</p>

		<p>The notation <m>\overline{E}</m> is used for the complement of an event <m>E</m>.</p>

		<p>We can compute the probability of the complement using <m>P(\overline{E}) = 1-P(E)</m></p>

		<p>Notice also that <m>P(E) = 1-P(\overline{E})</m></p>
</assemblage>

<example>
	<p>If you pull a random card from a deck of playing cards, what is the probability it is not a heart?</p>

	<p>There are 13 hearts in the deck, so P(heart)=<m>\frac{13}{52}=\frac{1}{4}</m></p>

	<p>The probability of not drawing a heart is in the complement:</p>

	<p>P(not heart) = 1-P(heart) = <m>1-\frac{1}{4}=\frac{3}{4}</m></p>
</example>

</subsection>

<subsection>
	<title>Probability of two independent events</title>

<example>
	<p>Suppose we flipped a coin and rolled a die, and wanted to know the probability of getting a head on the coin and a 6 on the die.</p>

	<p>We could list all possible outcomes:   {H1,H2,H3,H4,H5,H6,T1,T2,T3,T4,T5,T6}.</p>

	<p>Notice there are <m>2 \cdot 6 = 12</m> total outcomes. Out of these, only 1 is the desired outcome, so the probability is  <m>\frac{1}{12}</m>.</p>

</example>

<p>The prior example was looking at two independent events.</p>

<assemblage>
	<title>Indepdentent Events</title>
	<p>Events A and B are <term>independent events</term> if the probability of Event B occurring is the same whether or not Event A occurs.</p>
</assemblage>

<example>
	<p>Are these events independent?</p>

	<p><ol>
		<li>A fair coin is tossed two times.  The two events are (1) first toss is a head and (2) second toss is a head.</li>

		<li>The two events (1) "It will rain tomorrow in Houston" and (2) "It will rain tomorrow in Galveston” (a city near Houston).</li>

		<li>You draw a card from a deck, then draw a second card without replacing the first.</li>
	</ol></p>

<p>Solutions: </p>

	<p><ol>
		<li>The probability that a head comes up on the second toss is 1/2 regardless of whether or not a head came up on the first toss, so these events are independent.</li>

		<li>These events are not independent because it is more likely that it will rain in Galveston on days it rains in Houston than on days it does not.</li>

		<li>The probability of the second card being red depends on whether the first card is red or not, so these events are not independent.</li>
	</ol></p>
</example>

<p>When two events are independent, the probability of both occurring is the product of the probabilities of the individual events. </p>

<assemblage>
	<title>P(A and B) for indepdent events</title>

	<p>If events A and B are independent, then the probability of both A and B occurring is</p>

	<p><me>P(A \text{ and } B) = P(A) \cdot P(B)</me></p>

	<p>where P(A and B) is the probability of events A and B both occurring, P(A) is the probability of event A occurring, and P(B) is the probability of event B occurring.</p>
</assemblage>

<p>If you look back at the coin and die example from earlier, you can see how the number of outcomes of the first event multiplied by the number of outcomes in the second event multiplied to equal the total number of possible outcomes in the combined event.</p>

<example>
	<p>In your drawer you have 10 pairs of socks, 6 of which are white, and 7 tee shirts, 3 of which are white.  If you randomly reach in and pull out a pair of socks and a tee shirt, what is the probability both are white?</p>

	<p>The probability of choosing a white pair of socks is <m>\frac{6}{10}</m>.</p>

	<p>The probability of choosing a white tee shirt is  <m>\frac{3}{7}</m>.</p>

	<p>The probability of both being white is <m> \frac{6}{10} \cdot \frac{3}{7} = \frac{18}{70} = \frac{9}{35}</m></p>
</example>

<exploration>
	<p>A card is pulled a deck of cards and noted.  The card is then replaced, the deck is shuffled, and a second card is removed and noted.  What is the probability that both cards are Aces?</p>
</exploration>

<p>The previous examples looked at the probability of both events occurring.  Now we will look at the probability of either event occurring.</p>

<example>
	<p>Suppose we flipped a coin and rolled a die, and wanted to know the probability of getting a head on the coin or a 6 on the die.</p>

	<p>Here, there are still 12 possible outcomes: {H1,H2,H3,H4,H5,H6,T1,T2,T3,T4,T5,T6}</p>

	<p>By simply counting, we can see that 7 of the outcomes have a head on the coin or a 6 on the die or both – we use or inclusively here (these 7 outcomes are H1, H2, H3, H4, H5, H6, T6), so the probability is <m> \frac{7}{12}</m>. How could we have found this from the individual probabilities? </p>

	<p> As we would expect, <m> \frac{1}{2} </m> of these outcomes have a head, and <m> \frac{1}{6} </m> of these outcomes have a 6 on the die. If we add these, <m> \frac{1}{2} + \frac{1}{6} = \frac{6}{12}+ \frac{2}{12} = \frac{8}{12}</m>, which is not the correct probability. Looking at the outcomes we can see why:  the outcome H6 would have been counted twice, since it contains both a head and a 6; the probability of both a head and rolling a 6 is <m> \frac{1}{12} </m>. </p>

	<p>If we subtract out this double count, we have the correct probability: <m> \frac{8}{12}-\frac{1}{12} = \frac{7}{12} </m>. </p>
</example>

<assemblage>
	<title><m>P(A \text{ or } B)</m></title>

	<p>The The probability of either A or B occurring (or both) is

		<me> P(A \text{or} B) = P(A) + P(B) - P(A \text{ and } B) </me>
	</p>
</assemblage>

<example>
	<p>Suppose we draw one card from a standard deck. What is the probability that we get a Queen or a King?</p>

	<p>There are 4 Queens and 4 Kings in the deck, hence 8 outcomes corresponding to a Queen or King out of 52 possible outcomes. Thus the probability of drawing a Queen or a King is: <m>P(\text{King and Queen}) = \frac{8}{52} </m>. </p>

	<p>Note that in this case, there are no cards that are both a Queen and a King, so  <m>P(\text{King and Queen}) = 0</m>.  Using our probability rule, we could have said:

	<me> P(\text{King or Queen}) = P(\text{King}) + P(\text{Queen}) - P(\text{King and Queen}) = \frac{4}{52} + \frac{4}{52} - 0 = \frac{8}{52}</me> </p>
</example>

<p>In the last example, the events were <term>mutually exclusive</term> so <m>P(A \text{ or } B) = P(A) + P(B)</m>. </p>


<example>
	<p>Suppose we draw one card from a standard deck. What is the probability that we get a red card or a King?</p>

	<p>Half the cards are red, so <m>P(\text{red}) = \frac{26}{52}</m> </p>

	<p>There are four kings, so <m>P(\text{King}) = \frac{4}{52}</m></p>

	<p>There are two red kings, so <m>P(\text{Red and King}) = \frac{2}{52}</m></p>

	<p>We can then calculate

		<me>P(\text{Red or King}) = P(\text{red}) + P(\text{King}) - P(\text{Red and King}) = \frac{26}{52} + \frac{4}{52} - \frac{2}{52} = \frac{28}{52}</me>
	</p>
</example>

<exploration>
	<p>In your drawer you have 10 pairs of socks, 6 of which are white, and 7 tee shirts, 3 of which are white.  If you reach in and randomly grab a pair of socks and a tee shirt, what the probability at least one is white?</p>
</exploration>

<example>
	<p>The table below shows the number of survey subjects who have received and not received a speeding ticket in the last year, and the color of their car.  Find the probability that a randomly chosen person:

		<ol>
			<li>Has a red car <emph>and</emph> got a speeding ticket</li>
			<li>Has a red car <emph>or</emph> got a speeding ticket.</li>
		</ol>
	</p>

 <sidebyside>
  <tabular top="minor" left="minor" right="minor" halign="center">
    <row bottom="minor">
      <cell>

	  </cell>
      <cell>
        Speeding ticket
      </cell>
      <cell>
      	No speeding ticket
      </cell>
      <cell>
      	Total
      </cell>
    </row>
    <row bottom="minor">
      <cell>
      Red car
	  </cell>
      <cell>
        15
      </cell>
      <cell>
      	135
      </cell>
      <cell>
      	150
      </cell>
    </row>
     <row bottom="minor">
      <cell>
      Not red car
	  </cell>
      <cell>
        45
      </cell>
      <cell>
      	470
      </cell>
      <cell>
      	515
      </cell>
    </row>
     <row bottom="minor">
      <cell>
      Total
	  </cell>
      <cell>
        60
      </cell>
      <cell>
      	605
      </cell>
      <cell>
      	665
      </cell>
    </row>
  </tabular>
</sidebyside>

<p>We can see that 15 people of the 665 surveyed had both a red car and got a speeding ticket, so the probability is <m>\frac{15}{665} \approx 0.0226</m>. </p>

<p> Notice that having a red car and getting a speeding ticket are not independent events, so the probability of both of them occurring is not simply the product of probabilities of each one occurring.</p>

<p>We could answer this question by simply adding up the numbers:  15 people with red cars and speeding tickets + 135 with red cars but no ticket + 45 with a ticket but no red car = 195 people.  So the probability is  <m> \frac{195}{665} \approx 0.2932</m>.</p>

<p>We also could have found this probability by:
<me>P(\text{has a red car}) + P(\text{got a speeding ticket}) - P(
\text{had a red car and got a speeding ticket}) = \frac{150}{665}+\frac{60}{665}-\frac{15}{665} = \frac{195}{665}</me>.</p>
</example>

</subsection>

<subsection><title>Conditional Probability</title>

<p>Often it is required to compute the probability of an event given that another event has occurred. </p>

<example>
	<p>What is the probability that two cards drawn at random from a deck of playing cards will both be aces?</p>

	<p>It might seem that you could use the formula for the probability of two independent events and simply multiply <m> \frac{4}{52} \cdot \frac{4}{52} = \frac{1}{169}.</m> This would be incorrect, however, because the two events are not independent. If the first card drawn is an ace, then the probability that the second card is also an ace would be lower because there would only be three aces left in the deck.</p>

	<p> Once the first card chosen is an ace, the probability that the second card chosen is also an ace is called the <term>conditional probability</term> of drawing an ace. In this case the "condition" is that the first card is an ace. Symbolically, we write this as:
<m>P(\text{ace on second draw} \mid \text{an ace on the first draw}). </m> </p>

<p>The vertical bar "|" is read as "given," so the above expression is short for "The probability that an ace is drawn on the second draw given that an ace was drawn on the first draw." What is this probability?  After an ace is drawn on the first draw, there are 3 aces out of 51 total cards left. This means that the conditional probability of drawing an ace after one ace has already been drawn is  <m>\frac{3}{51} = \frac{1}{17} </m>. </p>

<p>Thus, the probability of both cards being aces is  <m> \frac{4}{52} \cdot \frac{3}{51} = \frac{12}{2652}= \frac{1}{221}</m>.</p>

</example>

<assemblage>
	<title>Conditional Probability</title>
	<p>If events <m>A</m> and <m>B</m> are not independent, then

		<me>P(A \text{ and } B) = P(A) \cdot P(B \mid A)</me></p>

</assemblage>

<example>
	<p>If you pull 2 cards out of a deck, what is the probability that both are spades?</p>

	<p>The probability that the first card is a spade is <m>\frac{13}{52}</m>.</p>

	<p> The probability that the second card is a spade, given the first was a spade, is  <m>\frac{12}{51}</m>, since there is one less spade in the deck, and one less total cards.</p>

	<p>The probability that both cards are spades is <m>\frac{13}{52}\cdot \frac{12}{51} = \frac{156}{2652} \approx 0.0588</m>.</p>

</example>


<example>
	<p>If you draw two cards from a deck, what is the probability that you will get the Ace of Diamonds and a black card? </p>

	<p>You can satisfy this condition by having Case A or Case B, as follows:
Case A) you can get the Ace of Diamonds first and then a black card or
Case B) you can get a black card first and then the Ace of Diamonds.
</p>

<p>
Let's calculate the probability of Case A. The probability that the first card is the Ace of Diamonds is  <m> \frac{1}{52}</m>. The probability that the second card is black given that the first card is the Ace of Diamonds is <m> \frac{26}{51} </m> because 26 of the remaining 51 cards are black. The probability is therefore  <m> \frac{1}{52} \cdot \frac{26}{51} = \frac{1}{102}.</m></p>

<p>Now for Case B: the probability that the first card is black is  <m>\frac{26}{52} = \frac{1}{2}</m>. The probability that the second card is the Ace of Diamonds given that the first card is black is <m> \frac{1}{51}</m>. The probability of Case B is therefore <m>\frac{1}{2} \cdot \frac{1}{51} = \frac{1}{102}</m>, the same as the probability of Case 1. </p>

<p>Recall that the probability of A or B is <m>P(A) + P(B) - P(A \text{ and} B)</m>.  In this problem, <m>P(A \text{ and } B) = 0</m> since the first card cannot be the Ace of Diamonds and be a black card.  Therefore, the probability of Case A or Case B is  <m> \frac{1}{102} + \frac{1}{102} = \frac{2}{102} = \frac{1}{51}</m>.  The probability that you will get the Ace of Diamonds and a black card when drawing two cards from a deck is <m>\frac{1}{51}</m>. </p>

</example>

<exploration>
	<p>In your drawer you have 10 pairs of socks, 6 of which are white.  If you reach in and randomly grab two pairs of socks, what is the probability that both are white?</p>
</exploration>

<example>

	<p>A home pregnancy test was given to women, then pregnancy was verified through blood tests.   The following table shows the home pregnancy test results.  Find

	<ol>
		<li><m>P(\text{not pregnant} \mid \text{positive test result})</m> </li>
		<li><m>P(\text{positive test result} \mid \text{not pregnant}) </m> </li>
	</ol>
</p>

	 <sidebyside>
  <tabular top="minor" left="minor" right="minor" halign="center">
    <row bottom="minor">
      <cell>

	  </cell>
      <cell>
       Positive test
      </cell>
      <cell>
      	Negative test
      </cell>
      <cell>
      	Total
      </cell>
    </row>
    <row bottom="minor">
      <cell>
      Pregnant
	  </cell>
      <cell>
        70
      </cell>
      <cell>
      	4
      </cell>
      <cell>
      	74
      </cell>
    </row>
     <row bottom="minor">
      <cell>
      Not pregnant
	  </cell>
      <cell>
        5
      </cell>
      <cell>
      	14
      </cell>
      <cell>
      	19
      </cell>
    </row>
     <row bottom="minor">
      <cell>
      Total
	  </cell>
      <cell>
        75
      </cell>
      <cell>
      	18
      </cell>
      <cell>
      	93
      </cell>
    </row>
  </tabular>
</sidebyside>

<p>
	<ol>
		<li> Since we know the test result was positive, we're limited to the 75 women in the first column, of which 5 were not pregnant.  <me> P(\text{not pregnant}
		\mid \text{positive test result}) = \frac{5}{75} \approx 0.067 . </me> </li>

		<li>Since we know the woman is not pregnant, we are limited to the 19 women in the second row, of which 5 had a positive test. <me> P(\text{positive test result} \mid \text{not pregnant}) = \frac{5}{19} \approx 0.263.</me> </li>

	</ol>
</p>

<p>The second result is what is usually called a false positive:  A positive result when the woman is not actually pregnant.</p>


</example>


</subsection>

-->

  </section>
